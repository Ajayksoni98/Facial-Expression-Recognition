{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"3\"\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import model_from_json  \n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables\n",
    "num_classes = 7 #angry, disgust, fear, happy, sad, surprise, neutral\n",
    "batch_size = 256\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances:  35888\n",
      "instance length:  2304\n"
     ]
    }
   ],
   "source": [
    "with open(\"fer2013.csv\") as f:\n",
    "    content = f.readlines()\n",
    "lines = np.array(content)\n",
    "num_of_instances = lines.size\n",
    "print(\"number of instances: \",num_of_instances)\n",
    "print(\"instance length: \",len(lines[1].split(\",\")[1].split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize trainset and test set\n",
    "x_train, y_train, x_test, y_test = [], [], [], []\n",
    "#------------------------------\n",
    "#transfer train and test set data\n",
    "for i in range(1,num_of_instances):\n",
    "    try:\n",
    "        emotion, img, usage = lines[i].split(\",\")      \n",
    "        val = img.split(\" \")      \n",
    "        pixels = np.array(val, 'float32')    \n",
    "        emotion = keras.utils.to_categorical(emotion, num_classes)\n",
    "        if 'Training' in usage:\n",
    "            y_train.append(emotion)\n",
    "            x_train.append(pixels)\n",
    "        elif 'PublicTest' in usage:\n",
    "            y_test.append(emotion)\n",
    "            x_test.append(pixels)\n",
    "    except:\n",
    "        print(\"\",end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Sequential()\n",
    "\n",
    "#1st convolution layer\n",
    "#model.add(Conv2D(64, (5, 5), activation='relu', input_shape=(48,48,1)))\n",
    "#model.add(MaxPooling2D(pool_size=(5,5), strides=(2, 2)))\n",
    "\n",
    "#2nd convolution layer\n",
    "#model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "#model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "#model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "#3rd convolution layer\n",
    "#model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "#model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "#model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "#model.add(Flatten())\n",
    "\n",
    "#fully connected neural networks\n",
    "#model.add(Dense(1024, activation='relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Dense(1024, activation='relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "#model.add(Dense(num_classes, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gen = ImageDataGenerator()\n",
    "#train_generator = gen.flow(x_train, y_train, batch_size=batch_size)\n",
    "\n",
    "#model.compile(loss='categorical_crossentropy'\n",
    " #   , optimizer=keras.optimizers.Adam()\n",
    "  #  , metrics=['accuracy']\n",
    "#)\n",
    "\n",
    "#fit = True\n",
    "#if fit == True:\n",
    " #   model.fit_generator(train_generator, steps_per_epoch=batch_size, epochs=epochs) #train for randomly selected one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709 train samples\n",
      "3589 test samples\n"
     ]
    }
   ],
   "source": [
    "#data transformation for train and test sets\n",
    "x_train = np.array(x_train, 'float32')\n",
    "y_train = np.array(y_train, 'float32')\n",
    "x_test = np.array(x_test, 'float32')\n",
    "y_test = np.array(y_test, 'float32')\n",
    "\n",
    "x_train /= 255 #normalize inputs between [0, 1]\n",
    "x_test /= 255\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 48, 48, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], 48, 48, 1)\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model on Disk and loading it back into the code\n",
    "# serialize model to JSON\n",
    "#model_json = model.to_json()\n",
    "#with open(\"model.json\", \"w\") as json_file:\n",
    "#    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "#model.save_weights(\"model.h5\")\n",
    "#print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "3589/3589 [==============================] - 5s 1ms/step\n",
      "Test loss: 0.27405645272947016\n",
      "Test accuracy: 88.85085677728576\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "loaded_model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "score1 = loaded_model.evaluate(x_test, y_test)\n",
    "print('Test loss:', score1[0])\n",
    "print('Test accuracy:', 100*score1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image.py:492: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Hp\\\\Desktop\\\\major project\\\\unnaa22.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-7c7070cf3567>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m22\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"C:\\Users\\Hp\\Desktop\\major project\\unnaa{k}.jpg\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrayscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m48\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m48\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image.py\u001b[0m in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[0;32m    496\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[0;32m    497\u001b[0m                           'The use of `array_to_img` requires PIL.')\n\u001b[1;32m--> 498\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    499\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'grayscale'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'L'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2541\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2542\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2543\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2544\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Hp\\\\Desktop\\\\major project\\\\unnaa22.jpg'"
     ]
    }
   ],
   "source": [
    "\n",
    "def emotion_analysis(emotions):\n",
    "    objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "    y_pos = np.arange(len(objects))\n",
    "    \n",
    "    plt.bar(y_pos, emotions, align='center', alpha=0.5)\n",
    "    plt.xticks(y_pos, objects)\n",
    "    plt.ylabel('percentage')\n",
    "    plt.title('emotion')\n",
    "    \n",
    "    plt.show()\n",
    "for i in range(22,25):\n",
    "    img = image.load_img(r\"C:\\Users\\Hp\\Desktop\\major project\\unnaa{k}.jpg\".format(k=i), grayscale=True, target_size=(48, 48))\n",
    "\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis = 0)\n",
    "\n",
    "    x /= 255\n",
    "\n",
    "    custom = loaded_model.predict(x)\n",
    "    emotion_analysis(custom[0])\n",
    "\n",
    "    x = np.array(x, 'float32')\n",
    "    x = x.reshape([48, 48]);\n",
    "\n",
    "    plt.gray()\n",
    "    plt.imshow(x)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shailesh Sharma\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image.py:492: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    }
   ],
   "source": [
    "def emotion_analysiss(emotions):\n",
    "    objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "    y_pos = np.arange(len(objects))\n",
    "    return y_pos\n",
    "import subprocess as sp\n",
    "sum_emotion = [0,0,0,0,0,0,0]\n",
    "for z in range(0,7):\n",
    "    for i in range(21,28):\n",
    "        img = image.load_img('C:/Users/Shailesh Sharma/Desktop/Minor/faces/unnaa{k}.jpg'.format(k=i), grayscale=True, target_size=(48, 48))\n",
    "        x = image.img_to_array(img)\n",
    "        y1=np.array(x).tolist()\n",
    "        x = np.expand_dims(x, axis = 0)\n",
    "        x /= 255\n",
    "        custom = loaded_model.predict(x)\n",
    "        y = emotion_analysiss(custom[0])\n",
    "        sum_emotion[z]=sum_emotion[z]+custom[0].tolist()[z]\n",
    "        #print(custom[0].tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sad', 3.2822255194187164)\n",
      "('neutral', 1.4264500737190247)\n",
      "('fear', 1.2291107401251793)\n"
     ]
    }
   ],
   "source": [
    "objects = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
    "dictword = dict(zip(objects,sum_emotion))\n",
    "from operator import itemgetter\n",
    "dict3 = sorted(dictword.items(), key = itemgetter(1), reverse=True)\n",
    "for i in range(0,3):\n",
    "    dict4 = dict3[i]\n",
    "    print(dict4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
